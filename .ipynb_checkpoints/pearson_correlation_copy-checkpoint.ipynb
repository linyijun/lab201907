{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading training and testing review data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './data/'\n",
    "\n",
    "# define file path\n",
    "train_file = os.path.join(data_path, 'review_train.csv')\n",
    "test_file = os.path.join(data_path, 'review_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read datasets\n",
    "train_data = pd.read_csv(train_file)\n",
    "test_data = pd.read_csv(test_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating business pairs for the Pearson correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notice that the similarity of (item1, item2) is the same as (item2, item1)\n",
    "# can reduce the number of pairs so as to reduce the computation\n",
    "\n",
    "users = list(set(train_data['uid']).intersection(set(test_data['uid'])))\n",
    "train_user_group = train_data.groupby('uid')\n",
    "test_user_group = test_data.groupby('uid')\n",
    "\n",
    "business_pairs = []\n",
    "for uid in users:\n",
    "    train_b_list = list(train_user_group.get_group(uid)['bid'])\n",
    "    test_b_list = list(test_user_group.get_group(uid)['bid'])\n",
    "    business_pairs += [sorted([a, b]) for a in train_b_list for b in test_b_list if a != b]\n",
    "\n",
    "# remove duplicates\n",
    "business_pairs_set = set(map(tuple, business_pairs))\n",
    "business_pairs = [list(x) for x in business_pairs_set]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the weight matrix (Pearson similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the review data into a dictionary {(uid, bid): rating}\n",
    "review_dict = {(row[0], row[1]): row[2] for row in train_data.values.tolist()}\n",
    "\n",
    "# map each business_id to a list of users rated on that {business_id: list[user_ids]}\n",
    "business_groups = train_data.groupby('bid')\n",
    "business_user_dict = {bid: list(business_groups.get_group(bid)['uid']) for bid in business_groups.groups}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to find common (co-rated) user list for two given businesses\n",
    "\n",
    "def find_co_rated_users(bid_1, bid_2):\n",
    "        \n",
    "    user_list_1 = business_user_dict.get(bid_1, [])\n",
    "    user_list_2 = business_user_dict.get(bid_2, [])\n",
    "    co_rated_users = set(user_list_1).intersection(set(user_list_2))\n",
    "    return co_rated_users\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to compute Pearson correlation\n",
    "\n",
    "import math\n",
    "\n",
    "def compute_pearson_correlation(rating_list_1, rating_list_2):\n",
    "\n",
    "    n_ele = len(rating_list_1)\n",
    "    avg_rating_1 = float(sum(rating_list_1))/float(len(rating_list_1))\n",
    "    avg_rating_2 = float(sum(rating_list_2))/float(len(rating_list_2))\n",
    "\n",
    "    var_star_1 = [x - avg_rating_1 for x in rating_list_1]\n",
    "    var_star_2 = [x - avg_rating_2 for x in rating_list_2]\n",
    "    weight_sum, weight_1, weight_2 = 0.0, 0.0, 0.0\n",
    "\n",
    "    for i in range(n_ele):\n",
    "        if var_star_1[i] * var_star_2[i] != 0.0:\n",
    "            weight_sum += var_star_1[i] * var_star_2[i]\n",
    "            weight_1 += var_star_1[i] * var_star_1[i]\n",
    "            weight_2 += var_star_2[i] * var_star_2[i]\n",
    "\n",
    "    if weight_1 == 0.0 or weight_2 == 0.0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return weight_sum / math.sqrt(weight_1) / math.sqrt(weight_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for computing weight matrix = 74.5968849658966.\n"
     ]
    }
   ],
   "source": [
    "# compute the Pearson correlation for each business pair\n",
    "\n",
    "import time\n",
    "\n",
    "weight_matrix = []\n",
    "PEARSON_THRED = 0.1\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for pair in business_pairs:\n",
    "    \n",
    "    bid_1, bid_2 = pair[0], pair[1]\n",
    "    \n",
    "    # fine the co-rated users\n",
    "    co_rated_users = find_co_rated_users(bid_1, bid_2) \n",
    "    \n",
    "    if len(co_rated_users) <= 1:\n",
    "        continue\n",
    "    \n",
    "    # get the rating list of the co-rated users\n",
    "    rating_list_1 = [review_dict[(u, bid_1)]for u in co_rated_users]\n",
    "    rating_list_2 = [review_dict[(u, bid_2)] for u in co_rated_users]\n",
    "\n",
    "    # compute the Pearson correlation\n",
    "    weight = compute_pearson_correlation(rating_list_1, rating_list_2)\n",
    "\n",
    "    if weight > PEARSON_THRED:  # you can set some threshold to filter the low correlated values\n",
    "        weight_matrix.append([bid_1, bid_2, weight])\n",
    "\n",
    "print('Time for computing weight matrix = {}.'.format(time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the results to a CSV file\n",
    "\n",
    "weight_matrix_df = pd.DataFrame(weight_matrix, columns=['bid1', 'bid2', 'corr'])\n",
    "weight_matrix_file_path = os.path.join(data_path, 'weight_matrix.csv')\n",
    "weight_matrix_df.to_csv(weight_matrix_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
